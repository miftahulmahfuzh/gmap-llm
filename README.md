# 🗺️ AI Places Finder with Google Maps

This project demonstrates how to build a powerful, interactive chatbot that uses a Large Language Model (LLM) to understand user requests and the Google Maps API to find real-world locations. The application is built with a robust, separated architecture: a FastAPI backend for reliable data fetching and a Streamlit frontend for a clean user interface.

## Features

-   **Natural Language Understanding**: Ask for places in plain English (or other languages), like "find me some good ramen spots in downtown san francisco".
-   **Real-time Google Maps Integration**: Fetches up-to-date information on locations, including names, addresses, and ratings.
-   **Reliable Map Links**: Generates clickable Google Maps links for directions to each location.
-   **Separation of Concerns**:
    -   **LLM (Intent Engine)**: Determines what the user wants.
    -   **FastAPI Backend (Data Engine)**: Acts as a secure "tool" to get structured data from Google.
    -   **Streamlit Frontend (Presentation Engine)**: Renders the data in a user-friendly, reliable way.
-   **Secure API Key Handling**: Uses environment variables to keep your secret keys safe.
-   **Easy Customization**: The AI's behavior and personality can be easily modified by editing a simple text file.

## How It Works

1.  The user types a request into the **Streamlit** frontend.
2.  The frontend sends the request to an **LLM** (like DeepSeek, via an OpenAI-compatible API).
3.  The LLM analyzes the request. If it's a location query, it decides to use the `find_places_on_map` tool.
4.  The Streamlit app calls our local **FastAPI** backend API with the search query generated by the LLM.
5.  The FastAPI server securely uses the **Google Maps API** to find places, then returns the results as structured JSON data.
6.  The Streamlit app receives this JSON data and uses **Python code** (not the LLM) to format it into a clean list with guaranteed, unbreakable map links for the user.

---

## Setup and Installation

Follow these steps to get the project running on your local machine.

### Step 1: Obtain API Keys

You will need two types of API keys for this project.

#### A. Google Maps API Key

1.  **Go to Google Cloud Console**: Navigate to the [Google Cloud Console](https://cloud.google.com/) and sign in with your Google account.
2.  **Create a New Project**: If you don't have one already, create a new project (e.g., `ai-places-finder`).
3.  **Enable Billing**: You must enable billing for your project. Google Cloud provides a generous free trial with credits, so you will not be charged unless you exceed the free tier limits.
4.  **Enable APIs**: In the navigation menu, go to **APIs & Services > Library** and search for and **enable** the following APIs:
    -   `Places API`
    -   `Geocoding API`
5.  **Create API Key**: Go to **APIs & Services > Credentials**, click **"+ CREATE CREDENTIALS"**, and select **"API key"**. Copy the generated key immediately.
6.  **Secure Your Key (Important!)**: Click on the new API key to edit it. Under **"API restrictions"**, select **"Restrict key"** and check the boxes only for the `Places API` and `Geocoding API`. This is a crucial security step.

#### B. LLM API Key

This project uses an LLM that is compatible with the OpenAI library. We used **DeepSeek** in our example.

1.  Sign up for an account on a platform like [DeepSeek](https://platform.deepseek.com/).
2.  Navigate to their API keys section and generate a new secret key.
3.  Copy the key.

### Step 2: Setup Python Environment and Install Dependencies

It is highly recommended to use a Python virtual environment.

1.  **Create a Virtual Environment**:
    ```bash
    python -m venv venv
    ```
2.  **Activate the Environment**:
    -   **On Windows**: `.\venv\Scripts\activate`
    -   **On macOS/Linux**: `source venv/bin/activate`

3.  **Create `requirements.txt`**: Create a file named `requirements.txt` in your project folder and add the following lines:
    ```txt
    fastapi
    uvicorn[standard]
    googlemaps
    python-dotenv
    openai
    requests
    streamlit
    ```
4.  **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

### Step 3: Configure Environment Variables

1.  Create a file named `.env` in the root of your project directory. **This file should never be committed to Git.**
2.  Add your secret API keys to this file as follows:

    ```
    GOOGLE_MAPS_API_KEY="PASTE_YOUR_GOOGLE_MAPS_API_KEY_HERE"
    DEEPSEEK_API_KEY="PASTE_YOUR_DEEPSEEK_OR_LLM_API_KEY_HERE"
    ```

---

## Running the Application

You need to run the backend and frontend simultaneously in two separate terminals. Make sure your virtual environment is activated in both.

### 1. Start the Backend API (FastAPI Tool)

This server acts as the "tool" that our AI can call.

In your **first terminal**, run the following command:
```bash
uvicorn main:app --reload
```
You should see a message indicating the server is running, usually on `http://127.0.0.1:8000`. Leave this terminal running.

### 2. Start the Frontend Chatbot (Streamlit)

This is the user-facing chat application.

In your **second terminal**, run the following command:
```bash
streamlit run frontend_app.py
```
A new tab should automatically open in your web browser at `http://localhost:8501`. You can now start chatting with your AI Places Finder!

## Project Structure

```
.
├── .env                  # Stores your secret API keys
├── frontend_app.py       # The Streamlit frontend application
├── main.py               # The FastAPI backend API (our "tool")
├── requirements.txt      # List of Python dependencies
└── system_prompt.txt     # The instructions for the AI's behavior
```
